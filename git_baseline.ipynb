{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c7a5ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook, tqdm_pandas\n",
    "import random\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "import ast\n",
    "from ast import literal_eval\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_validate, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a6b1866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred):\n",
    "    score = []\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "    specificity = tn/(tn + fp)\n",
    "    roc_auc = roc_auc_score(y_test, pred)\n",
    "\n",
    "    score = [accuracy, precision, recall, f1, specificity, roc_auc, tn, tp, fn, fp]\n",
    "    return score\n",
    "def get_mean(score):\n",
    "    for i in range(5):\n",
    "        accuracy = score[i][0]\n",
    "        precision = score[i][1]\n",
    "        recall = score[i][2]\n",
    "        f1 = score[i][3]\n",
    "        specificity = score[i][4]\n",
    "        roc_auc = score[i][5]\n",
    "        tn = score[i][6]\n",
    "        tp = score[i][7]\n",
    "        fn = score[i][8]\n",
    "        fp = score[i][9]\n",
    "\n",
    "    print(\"accuracy: \"+str(np.mean(accuracy))+\", precision: \"+str(np.mean(precision))+\", recall: \"+str(np.mean(recall))+\", f1: \"+str(np.mean(f1))+\", specificity\"+str(np.mean(specificity))+\", roc_auc: \"+str(np.mean(roc_auc))+\", tn: \"+str(np.mean(tn)) + \"tp: \"+str(np.mean(tp)) + \"fn: \"+str(np.mean(fn)) + \"fp: \"+str(np.mean(fp)))\n",
    "    return (\"accuracy: \"+str(np.mean(accuracy))+\", precision: \"+str(np.mean(precision))+\", recall: \"+str(np.mean(recall))+\", f1: \"+str(np.mean(f1))+\", specificity\"+str(np.mean(specificity))+\", roc_auc: \"+str(np.mean(roc_auc))+\n",
    "           \", tn: \"+str(np.mean(tn)) + \", tp: \"+str(np.mean(tp)) + \", fn: \"+str(np.mean(fn)) + \", fp: \"+str(np.mean(fp)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8005b0e6",
   "metadata": {},
   "source": [
    "## Experience 1 -> all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "384bd809",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('use_data/final_use.csv', encoding = 'utf-8-sig', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbafa50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['review_rating', 'Affect', 'Cognition',\n",
    "       'Social', 'Perception', 'motion', 'Psychological Distancing','depth', 'style', 'review_extremity', 'photo',\n",
    "       'text_structure', 'reputation', 'experience', 'location' ]]\n",
    "\n",
    "y = df[['fake']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 215, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42976a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(inplace = True, drop=True)\n",
    "X_test.reset_index(inplace = True, drop=True)\n",
    "y_train.reset_index(inplace = True, drop=True)\n",
    "y_test.reset_index(inplace = True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e90cf9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9197152003532398,\n",
       " 0.6632855022266205,\n",
       " 0.311998138019318,\n",
       " 0.42437673130193904,\n",
       " 0.9834018317743332,\n",
       " 0.6476999848968256,\n",
       " 80636,\n",
       " 2681,\n",
       " 5912,\n",
       " 1361]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clssifier = xgb.XGBClassifier(n_estimators=100)\n",
    "xg_clssifier.fit(X_train, y_train)\n",
    "pred_xgb = xg_clssifier.predict(X_test)\n",
    "get_clf_eval(y_test, pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfbd256a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.25824042388784635,\n",
       " 0.1096724346934154,\n",
       " 0.9581054346561154,\n",
       " 0.19681575864789272,\n",
       " 0.18489700842713758,\n",
       " 0.5715012215416265,\n",
       " 15161,\n",
       " 8233,\n",
       " 360,\n",
       " 66836]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clasiifier = SVC(max_iter=100)\n",
    "\n",
    "svm_clasiifier.fit(X_train, y_train)\n",
    "pred_svm = svm_clasiifier.predict(X_test)\n",
    "get_clf_eval(y_test, pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75035f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9187106744673805,\n",
       " 0.6613284326594907,\n",
       " 0.29314558361457,\n",
       " 0.40622480245121756,\n",
       " 0.9842677171116017,\n",
       " 0.6387066503630858,\n",
       " 80707,\n",
       " 2519,\n",
       " 6074,\n",
       " 1290]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators = 100)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "pred_rf = rf_classifier.predict(X_test)\n",
    "get_clf_eval(y_test, pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e66bd1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9074401148029584,\n",
       " 0.6947565543071161,\n",
       " 0.04317467706272547,\n",
       " 0.08129724991782622,\n",
       " 0.9980121223947218,\n",
       " 0.5205933997287236,\n",
       " 81834,\n",
       " 371,\n",
       " 8222,\n",
       " 163]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "pred_lr = LR.predict(X_test)\n",
    "get_clf_eval(y_test, pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6dbdbcb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.904150568495419,\n",
       " 0.488905325443787,\n",
       " 0.23076923076923078,\n",
       " 0.3135425725353783,\n",
       " 0.9747185872653877,\n",
       " 0.6027439090173092,\n",
       " 79924,\n",
       " 1983,\n",
       " 6610,\n",
       " 2073]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KNN = KNeighborsClassifier()\n",
    "KNN.fit(X_train, y_train)\n",
    "pred_KNN = KNN.predict(X_test)\n",
    "get_clf_eval(y_test, pred_KNN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
